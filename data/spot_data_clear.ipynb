{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T19:53:55.689071Z",
     "start_time": "2025-04-28T19:53:55.513711Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# CSV 파일의 경우 먼저 pandas로 읽은 후 GeoDataFrame으로 변환해야 합니다\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일을 pandas DataFrame으로 읽기\n",
    "df = pd.read_csv('accident_cleaned.csv', encoding='utf-8-sig')\n",
    "#print(df.head())\n",
    "#print(df)\n",
    "# 만약 CSV 파일에 geometry 정보가 있다면 (예: 위도/경도)\n",
    "# 적절한 방식으로 GeoDataFrame으로 변환해야 합니다\n",
    "#df['사고다발지역시도시군구']\n",
    "\n",
    "import json\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.wkt import loads\n",
    "\n",
    "\n",
    "# 폴리곤 정보를 GeoJSON으로 변환하는 함수\n",
    "def create_polygon(polygon_str):\n",
    "        polygon_json = polygon_str.replace('type:', '\"type\":').replace('coordinates:', '\"coordinates\":').replace('Polygon', '\"Polygon\"')\n",
    "        geojson = json.loads(polygon_json)\n",
    "        return Polygon(geojson['coordinates'][0])\n",
    "\n",
    "\n",
    "df['사고다발지역폴리곤정보'] = df['사고다발지역폴리곤정보'].apply(create_polygon)\n",
    "gdf = gpd.GeoDataFrame(df[['사고다발지역시도시군구']], geometry=df['사고다발지역폴리곤정보'], crs=\"EPSG:4326\")\n",
    "print(gdf)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mJSONDecodeError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m     23\u001B[39m         geojson = json.loads(polygon_json)\n\u001B[32m     24\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m Polygon(geojson[\u001B[33m'\u001B[39m\u001B[33mcoordinates\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33m사고다발지역폴리곤정보\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m사고다발지역폴리곤정보\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_polygon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m gdf = gpd.GeoDataFrame(df[[\u001B[33m'\u001B[39m\u001B[33m사고다발지역시도시군구\u001B[39m\u001B[33m'\u001B[39m]], geometry=df[\u001B[33m'\u001B[39m\u001B[33m사고다발지역폴리곤정보\u001B[39m\u001B[33m'\u001B[39m], crs=\u001B[33m\"\u001B[39m\u001B[33mEPSG:4326\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(gdf)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4919\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4920\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4921\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4922\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4923\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1508\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1509\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 23\u001B[39m, in \u001B[36mcreate_polygon\u001B[39m\u001B[34m(polygon_str)\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mcreate_polygon\u001B[39m(polygon_str):\n\u001B[32m     22\u001B[39m         polygon_json = polygon_str.replace(\u001B[33m'\u001B[39m\u001B[33mtype:\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtype\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m'\u001B[39m).replace(\u001B[33m'\u001B[39m\u001B[33mcoordinates:\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mcoordinates\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m'\u001B[39m).replace(\u001B[33m'\u001B[39m\u001B[33mPolygon\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPolygon\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m         geojson = \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolygon_json\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m Polygon(geojson[\u001B[33m'\u001B[39m\u001B[33mcoordinates\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\__init__.py:346\u001B[39m, in \u001B[36mloads\u001B[39m\u001B[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[39m\n\u001B[32m    341\u001B[39m     s = s.decode(detect_encoding(s), \u001B[33m'\u001B[39m\u001B[33msurrogatepass\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    344\u001B[39m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    345\u001B[39m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[32m--> \u001B[39m\u001B[32m346\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    348\u001B[39m     \u001B[38;5;28mcls\u001B[39m = JSONDecoder\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\decoder.py:338\u001B[39m, in \u001B[36mJSONDecoder.decode\u001B[39m\u001B[34m(self, s, _w)\u001B[39m\n\u001B[32m    333\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w=WHITESPACE.match):\n\u001B[32m    334\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[32m    335\u001B[39m \u001B[33;03m    containing a JSON document).\u001B[39;00m\n\u001B[32m    336\u001B[39m \n\u001B[32m    337\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m338\u001B[39m     obj, end = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    339\u001B[39m     end = _w(s, end).end()\n\u001B[32m    340\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m end != \u001B[38;5;28mlen\u001B[39m(s):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\decoder.py:356\u001B[39m, in \u001B[36mJSONDecoder.raw_decode\u001B[39m\u001B[34m(self, s, idx)\u001B[39m\n\u001B[32m    354\u001B[39m     obj, end = \u001B[38;5;28mself\u001B[39m.scan_once(s, idx)\n\u001B[32m    355\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m356\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[33m\"\u001B[39m\u001B[33mExpecting value\u001B[39m\u001B[33m\"\u001B[39m, s, err.value) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    357\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[31mJSONDecodeError\u001B[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:18:24.625929Z",
     "start_time": "2025-04-28T07:18:24.494586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# cp949로 읽어서\n",
    "df = pd.read_csv('accident.csv', encoding='cp949')\n",
    "\n",
    "# utf-8로 저장\n",
    "df.to_csv('accident.csv', index=False, encoding='utf-8')"
   ],
   "id": "9afff81348770626",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:18:31.648061Z",
     "start_time": "2025-04-28T07:18:31.601062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./accident.csv', encoding='utf-8')\n",
    "print(df.head())"
   ],
   "id": "b60b6c1690c38c07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   사고지역관리번호  사고연도 사고유형구분      위치코드 사고다발지역시도시군구                       사고지역위치명  \\\n",
      "0   2020037  2019    자전거  11500004  서울특별시 강서구4     서울특별시 강서구 등촌동(거산하이빌입구 부근)   \n",
      "1   2020037  2019    자전거  11530001  서울특별시 구로구1  서울특별시 구로구 구로동(구로구영등포구경계5 부근)   \n",
      "2   2020037  2019    자전거  11530002  서울특별시 구로구2  서울특별시 구로구 구로동(신구로주유소가마산길 부근)   \n",
      "3   2020037  2019    자전거  11530003  서울특별시 구로구3   서울특별시 구로구 신도림동(신성은하수아파트 부근)   \n",
      "4   2020037  2019    자전거  11530004  서울특별시 구로구4      서울특별시 구로구 고척동(센츄리아파트 부근)   \n",
      "\n",
      "   사고건수  사상자수  사망자수  중상자수  경상자수  부상신고자수         위도          경도  \\\n",
      "0     4     4     0     0     4       0  37.546783  126.860030   \n",
      "1     6     6     0     4     2       0  37.507329  126.893677   \n",
      "2     6     6     0     4     0       2  37.497455  126.892645   \n",
      "3     5     6     0     1     4       1  37.508012  126.886498   \n",
      "4     5     6     0     1     4       1  37.505240  126.861102   \n",
      "\n",
      "                                         사고다발지역폴리곤정보     데이터기준일자   제공기관코드  \\\n",
      "0  {type:Polygon,coordinates:[[[126.86182652,37.5...  2024-09-09  B555234   \n",
      "1  {type:Polygon,coordinates:[[[126.89547351,37.5...  2024-09-09  B555234   \n",
      "2  {type:Polygon,coordinates:[[[126.89444186,37.4...  2024-09-09  B555234   \n",
      "3  {type:Polygon,coordinates:[[[126.88829421,37.5...  2024-09-09  B555234   \n",
      "4  {type:Polygon,coordinates:[[[126.86289859,37.5...  2024-09-09  B555234   \n",
      "\n",
      "      제공기관명  \n",
      "0  한국도로교통공단  \n",
      "1  한국도로교통공단  \n",
      "2  한국도로교통공단  \n",
      "3  한국도로교통공단  \n",
      "4  한국도로교통공단  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:18:52.157714Z",
     "start_time": "2025-04-28T07:18:52.146650Z"
    }
   },
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "76c549570b08c2c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "사고지역관리번호       0\n",
       "사고연도           0\n",
       "사고유형구분         0\n",
       "위치코드           0\n",
       "사고다발지역시도시군구    0\n",
       "사고지역위치명        0\n",
       "사고건수           0\n",
       "사상자수           0\n",
       "사망자수           0\n",
       "중상자수           0\n",
       "경상자수           0\n",
       "부상신고자수         0\n",
       "위도             0\n",
       "경도             0\n",
       "사고다발지역폴리곤정보    0\n",
       "데이터기준일자        0\n",
       "제공기관코드         0\n",
       "제공기관명          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T08:23:35.244077Z",
     "start_time": "2025-04-28T08:23:35.235826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_keep = ['사고다발지역시도시군구', '위도', '경도', '사고다발지역폴리곤정보']\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "print(df.head())"
   ],
   "id": "f306da7cb210b4b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  사고다발지역시도시군구         위도          경도  \\\n",
      "0  서울특별시 강서구4  37.546783  126.860030   \n",
      "1  서울특별시 구로구1  37.507329  126.893677   \n",
      "2  서울특별시 구로구2  37.497455  126.892645   \n",
      "3  서울특별시 구로구3  37.508012  126.886498   \n",
      "4  서울특별시 구로구4  37.505240  126.861102   \n",
      "\n",
      "                                         사고다발지역폴리곤정보  \n",
      "0  POLYGON ((126.86182652 37.54678319, 126.861792...  \n",
      "1  POLYGON ((126.89547351 37.50732852, 126.895438...  \n",
      "2  POLYGON ((126.89444186 37.49745453, 126.894407...  \n",
      "3  POLYGON ((126.88829421 37.50801244, 126.888259...  \n",
      "4  POLYGON ((126.86289859 37.50524013, 126.862864...  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T08:24:15.677589Z",
     "start_time": "2025-04-28T08:24:15.619203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.to_csv('accident_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(df.head())"
   ],
   "id": "3e99b55bba88f2c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  사고다발지역시도시군구         위도          경도  \\\n",
      "0  서울특별시 강서구4  37.546783  126.860030   \n",
      "1  서울특별시 구로구1  37.507329  126.893677   \n",
      "2  서울특별시 구로구2  37.497455  126.892645   \n",
      "3  서울특별시 구로구3  37.508012  126.886498   \n",
      "4  서울특별시 구로구4  37.505240  126.861102   \n",
      "\n",
      "                                         사고다발지역폴리곤정보  \n",
      "0  POLYGON ((126.86182652 37.54678319, 126.861792...  \n",
      "1  POLYGON ((126.89547351 37.50732852, 126.895438...  \n",
      "2  POLYGON ((126.89444186 37.49745453, 126.894407...  \n",
      "3  POLYGON ((126.88829421 37.50801244, 126.888259...  \n",
      "4  POLYGON ((126.86289859 37.50524013, 126.862864...  \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:01:53.070005Z",
     "start_time": "2025-04-28T20:01:52.874832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# CSV 파일의 경우 먼저 pandas로 읽은 후 GeoDataFrame으로 변환해야 합니다\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일을 pandas DataFrame으로 읽기\n",
    "df = pd.read_csv('accident_cleaned.csv', encoding='utf-8-sig')\n",
    "#print(df.head())\n",
    "#print(df)\n",
    "# 만약 CSV 파일에 geometry 정보가 있다면 (예: 위도/경도)\n",
    "# 적절한 방식으로 GeoDataFrame으로 변환해야 합니다\n",
    "#df['사고다발지역시도시군구']\n",
    "\n",
    "import json\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.wkt import loads\n",
    "\n",
    "\n",
    "# 폴리곤 정보를 GeoJSON으로 변환하는 함수\n",
    "def create_polygon(polygon_str):\n",
    "        polygon_json = polygon_str.replace('type:', '\"type\":').replace('coordinates:', '\"coordinates\":').replace('Polygon', '\"Polygon\"')\n",
    "        geojson = json.loads(polygon_json)\n",
    "        polygon = Polygon(geojson['coordinates'][0])\n",
    "        return polygon.wkt\n",
    "\n",
    "df['사고다발지역폴리곤정보'] = df['사고다발지역폴리곤정보'].apply(create_polygon)\n",
    "# gdf = gpd.GeoDataFrame(df[['사고다발지역시도시군구']], geometry=df['사고다발지역폴리곤정보'], crs=\"EPSG:4326\")\n",
    "# print(gdf)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "# df = pd.read_csv('accident_cleaned.csv')\n",
    "\n",
    "engine = create_engine('mysql+pymysql://skn14:skn14@localhost:3306/accidentdb', echo=True)\n",
    "\n",
    "df.to_sql(name='tbl_spot', con=engine, if_exists='replace', index=False)"
   ],
   "id": "913f8d3c5197f616",
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mJSONDecodeError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m     24\u001B[39m         polygon = Polygon(geojson[\u001B[33m'\u001B[39m\u001B[33mcoordinates\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m])\n\u001B[32m     25\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m polygon.wkt\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33m사고다발지역폴리곤정보\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m사고다발지역폴리곤정보\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_polygon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m# gdf = gpd.GeoDataFrame(df[['사고다발지역시도시군구']], geometry=df['사고다발지역폴리곤정보'], crs=\"EPSG:4326\")\u001B[39;00m\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# print(gdf)\u001B[39;00m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[34;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[34;01mpd\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4919\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4920\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4921\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4922\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4923\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1508\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1509\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 23\u001B[39m, in \u001B[36mcreate_polygon\u001B[39m\u001B[34m(polygon_str)\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mcreate_polygon\u001B[39m(polygon_str):\n\u001B[32m     22\u001B[39m         polygon_json = polygon_str.replace(\u001B[33m'\u001B[39m\u001B[33mtype:\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtype\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m'\u001B[39m).replace(\u001B[33m'\u001B[39m\u001B[33mcoordinates:\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mcoordinates\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m'\u001B[39m).replace(\u001B[33m'\u001B[39m\u001B[33mPolygon\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPolygon\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m         geojson = \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolygon_json\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m         polygon = Polygon(geojson[\u001B[33m'\u001B[39m\u001B[33mcoordinates\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m])\n\u001B[32m     25\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m polygon.wkt\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\__init__.py:346\u001B[39m, in \u001B[36mloads\u001B[39m\u001B[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[39m\n\u001B[32m    341\u001B[39m     s = s.decode(detect_encoding(s), \u001B[33m'\u001B[39m\u001B[33msurrogatepass\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    344\u001B[39m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    345\u001B[39m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[32m--> \u001B[39m\u001B[32m346\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    348\u001B[39m     \u001B[38;5;28mcls\u001B[39m = JSONDecoder\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\decoder.py:338\u001B[39m, in \u001B[36mJSONDecoder.decode\u001B[39m\u001B[34m(self, s, _w)\u001B[39m\n\u001B[32m    333\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w=WHITESPACE.match):\n\u001B[32m    334\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[32m    335\u001B[39m \u001B[33;03m    containing a JSON document).\u001B[39;00m\n\u001B[32m    336\u001B[39m \n\u001B[32m    337\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m338\u001B[39m     obj, end = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    339\u001B[39m     end = _w(s, end).end()\n\u001B[32m    340\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m end != \u001B[38;5;28mlen\u001B[39m(s):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\decoder.py:356\u001B[39m, in \u001B[36mJSONDecoder.raw_decode\u001B[39m\u001B[34m(self, s, idx)\u001B[39m\n\u001B[32m    354\u001B[39m     obj, end = \u001B[38;5;28mself\u001B[39m.scan_once(s, idx)\n\u001B[32m    355\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m356\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[33m\"\u001B[39m\u001B[33mExpecting value\u001B[39m\u001B[33m\"\u001B[39m, s, err.value) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    357\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[31mJSONDecodeError\u001B[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:04:25.208625Z",
     "start_time": "2025-04-28T20:04:24.523248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "\n",
    "# 1. CSV 파일 읽기\n",
    "df = pd.read_csv('accident_cleaned.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 2. 시도 / 시군구 분리\n",
    "def split_region(full_name):\n",
    "    match = re.match(r'([^\\s]+)\\s(.+)', full_name)\n",
    "    if match:\n",
    "        sido = match.group(1)\n",
    "        sigungu = re.sub(r'\\d+', '', match.group(2))\n",
    "        return sido, sigungu\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "df[['시도', '시군구']] = df['사고다발지역시도시군구'].apply(lambda x: pd.Series(split_region(x)))\n",
    "\n",
    "# 3. 필요한 컬럼만 선택\n",
    "df_simple = df[['시도', '시군구', '위도', '경도', '사고다발지역폴리곤정보']]\n",
    "\n",
    "# 4. DB 연결\n",
    "engine = create_engine('mysql+pymysql://skn14:skn14@localhost:3306/accidentdb')\n",
    "\n",
    "# 5. 테이블에 한번에 넣기\n",
    "df_simple.to_sql(name='tbl_spot', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"DB에 데이터 전부 INSERT 완료!\")\n"
   ],
   "id": "22fd44c84dacc9a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB에 데이터 전부 INSERT 완료!\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T20:38:52.880333Z",
     "start_time": "2025-04-28T20:38:52.351258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.wkt import loads\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "def clean_sido_name(sido_name):\n",
    "    if sido_name.startswith('충청남도'):\n",
    "        return '충남'\n",
    "    elif sido_name.startswith('충청북도'):\n",
    "        return '충북'\n",
    "    elif sido_name.startswith('전라남도'):\n",
    "        return '전남'\n",
    "    elif sido_name.startswith('전라북도'):\n",
    "        return '전북'\n",
    "    elif sido_name.startswith('경상남도'):\n",
    "        return '경남'\n",
    "    elif sido_name.startswith('경상북도'):\n",
    "        return '경북'\n",
    "    # 소괄호로 튜플로 묶고 해당 값을 보내야 함\n",
    "    elif sido_name.endswith(('특별자치시', '특별자치도', '특별시', '광역시', '도')):\n",
    "        return sido_name[:2]\n",
    "    else:\n",
    "        return sido_name\n",
    "\n",
    "\n",
    "df = pd.read_csv('accident_cleaned.csv', encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "# 시도명 클린\n",
    "split_df = df['사고다발지역시도시군구'].str.split(' ', n=1, expand=True)\n",
    "df['사고다발지역시도'] = split_df[0].apply(lambda x: clean_sido_name(str(x)))\n",
    "df['사고다발지역시군구'] = split_df[1]\n",
    "\n",
    "# 시군구명 클린\n",
    "df['사고다발지역시군구'] = split_df[1].str.extract(r'([가-힣]+[시군구])')\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "df_simple = df[['사고다발지역시도', '사고다발지역시군구', '위도', '경도', '사고다발지역폴리곤정보']]\n",
    "\n",
    "# DB 연결\n",
    "engine = create_engine('mysql+pymysql://skn14:skn14@localhost:3306/accidentdb')\n",
    "\n",
    "# 테이블에 한번에 넣기\n",
    "df_simple.to_sql(name='tbl_spot', con=engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"DB에 데이터 전부 INSERT 완료!\")"
   ],
   "id": "f867673012c5698e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB에 데이터 전부 INSERT 완료!\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```sql\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ],
   "id": "503e3b1f25792803"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
